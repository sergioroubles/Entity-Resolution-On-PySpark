{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inicialización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc=SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros:  32152\n"
     ]
    }
   ],
   "source": [
    "rdd_derecho=sc.textFile('cociente_clean_uniform_od.csv').map(lambda x: x.split(';'))\n",
    "rdd_derecho=rdd_derecho.map(lambda x: [x[0], x[1],x[2],x[3],eval(x[4])])\n",
    "print('Número de registros: ', rdd_derecho.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros:  34782\n"
     ]
    }
   ],
   "source": [
    "rdd_izquierdo=sc.textFile('cociente_clean_uniform_oi.csv').map(lambda x: x.split(';'))\n",
    "rdd_izquierdo=rdd_izquierdo.map(lambda x: [x[0], x[1],x[2],x[3],eval(x[4])])\n",
    "print('Número de registros: ', rdd_izquierdo.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rutinas necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_complejo(x,y,npiv):\n",
    "    if npiv==0:\n",
    "        if x[2]==y[2]:\n",
    "            if x[1]==y[1] or x[0]==y[0]:\n",
    "                return True\n",
    "            else:\n",
    "                if fuzz.ratio(x[1],y[1])>90:\n",
    "                    return True\n",
    "                if fuzz.ratio(x[0],y[0])>90:\n",
    "                    return True\n",
    "            return False\n",
    "        else:\n",
    "            if fuzz.ratio(x[0],y[0])>90:\n",
    "                if fuzz.ratio(x[1],y[1])>90:\n",
    "                    return True\n",
    "            return False\n",
    "    if npiv==1 or npiv==2:\n",
    "        if x[0]==y[0]:\n",
    "            if x[2]==y[2]:\n",
    "                return True\n",
    "            if fuzz.ratio(x[1],y[1])>90:\n",
    "                return True\n",
    "        elif x[2]==y[2]:\n",
    "            if fuzz.ratio(x[1],y[1])>90:\n",
    "                return True\n",
    "        return False\n",
    "    if npiv==3:\n",
    "        if x[0]==y[0]:\n",
    "            if x[1]==y[1] or x[2]==y[2]:\n",
    "                return True\n",
    "            else:\n",
    "                if fuzz.ratio(x[1],y[1])>90:\n",
    "                    return True\n",
    "                if fuzz.ratio(x[2],y[2])>90:\n",
    "                    return True\n",
    "            return False\n",
    "        else:\n",
    "            if fuzz.ratio(x[2],y[2])>90:\n",
    "                if fuzz.ratio(x[1],y[1])>90:\n",
    "                    return True\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clave_valor(x,npiv):\n",
    "    clave=x[npiv]\n",
    "    del x[npiv]\n",
    "    return [clave,x]\n",
    "\n",
    "def clave_valor_inversa(x,npiv):\n",
    "    x[1].insert(npiv,x[0])\n",
    "    return x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(x,npiv,funcion_matching):\n",
    "    if len(x[1])==1:                          \n",
    "        return (x[0],list(x[1]))\n",
    "    else:                                      \n",
    "        lista=list(x[1])\n",
    "        for i in reversed(range(len(lista))):            \n",
    "            for j in range(0,i):\n",
    "                if funcion_matching(lista[i],lista[j],npiv):\n",
    "                    lista=merge(lista,i,j)\n",
    "                    break\n",
    "        return (x[0],lista) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(lista,i,j):\n",
    "    if len(lista[j][3])>len(lista[i][3]):\n",
    "        lista[j][3]|=lista[i][3];\n",
    "    elif len(lista[j][3])<len(lista[i][3]):\n",
    "        lista[i][3]|=lista[j][3];\n",
    "        lista[j]=lista[i];\n",
    "    else:\n",
    "        if lista[i][1]>=lista[j][1]:\n",
    "            lista[j][1]=lista[i][1]\n",
    "        if lista[i][0]>=lista[j][0]:\n",
    "            lista[j][0]=lista[i][0]\n",
    "        if lista[i][2]>=lista[j][2]:\n",
    "            lista[j][1]=lista[i][1]\n",
    "    \n",
    "    del lista[i];\n",
    "    return lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pivote_info(rdd,npiv,funcion_matching):\n",
    "    nreg=rdd.count()\n",
    "    t=time.time()\n",
    "    \n",
    "    rdd2=rdd.map(lambda x: clave_valor(x,npiv)).groupByKey()\n",
    "    bloques=rdd2.count()\n",
    "    comparaciones=rdd2.map(lambda x: len(list(x[1]))**2).sum()\n",
    "    rdd2=rdd2.map(lambda x: compare(x,npiv,funcion_matching)).flatMapValues(lambda x: x).map(lambda x: clave_valor_inversa(x,npiv))\n",
    "    \n",
    "    tiempo=time.time()-t\n",
    "    nfinal=rdd2.count()\n",
    "    duplicados=nreg-nfinal\n",
    "    info=[round(tiempo,2),duplicados,nfinal,bloques,round(nreg/bloques,2),comparaciones,round(duplicados**2/comparaciones)]\n",
    "    return rdd2, info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejecución "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.22, 5548, 26604, 15207, 2.11, 101838, 302]\n",
      "[0.83, 3198, 23406, 18862, 1.41, 83810, 122]\n",
      "[0.68, 98, 23308, 3652, 6.41, 2814546, 0]\n",
      "[0.95, 1, 23307, 22129, 1.05, 932936, 0]\n",
      "8845\n",
      "[0.95, 6755, 28027, 15616, 2.23, 118832, 384]\n",
      "[0.83, 4162, 23865, 19050, 1.47, 95639, 181]\n",
      "[0.56, 173, 23692, 3699, 6.45, 2926167, 0]\n",
      "[0.85, 2, 23690, 22333, 1.06, 1140502, 0]\n",
      "11092\n"
     ]
    }
   ],
   "source": [
    "rdd_derecho_final=rdd_derecho\n",
    "errores=[0]*4\n",
    "for i in [3,1,2,0]:\n",
    "    rdd_derecho_final,info=pivote_info(rdd_derecho_final,i,match_complejo)\n",
    "    print(info)\n",
    "    errores[i]=info[1]    \n",
    "print(sum(errores))\n",
    "\n",
    "rdd_izquierdo_final=rdd_izquierdo\n",
    "errores=[0]*4\n",
    "for i in [3,1,2,0]:\n",
    "    rdd_izquierdo_final,info=pivote_info(rdd_izquierdo_final,i,match_complejo)\n",
    "    print(info)\n",
    "    errores[i]=info[1]    \n",
    "print(sum(errores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos por este \"camino\" 8835 y 11089 errores, bastante bien frente a los detectados por enfoque bruto\n",
    "\n",
    "Nota: al cambiar el fichero original de datos a utf8 y rehacer todo el procesado,\n",
    "los números son ligeramente diferentes 8845 y 11092, en todo caso al alza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_rdd_to_csv(rdd, file_name, n_muestras=1):\n",
    "    with open(file_name, 'w') as f:\n",
    "        for id,apellidos,nombre,fecha_nac,muestras in rdd.collect():\n",
    "            if len(muestras) >= n_muestras:\n",
    "                result = ';'.join([str(id),apellidos,nombre,fecha_nac]+[repr(muestras)])\n",
    "                print(result, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_rdd_to_csv(rdd_derecho_final, \"merged_cociente_clean_uniform_od.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Postprocesado final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay menos de 1000 registros sin número de historia, podemos ver si los apellidos\n",
    "y la fecha de nacimiento coinciden con algún otro campo. \n",
    "\n",
    "Estoy seguro de que podría integrarse en match complejo..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recuperación de los datos de las campimetrías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recover_from_index(name, index_set):\n",
    "    result = []\n",
    "    with open(name) as input_file:\n",
    "        for line in input_file:\n",
    "            if int(line.split(';')[0]) in index_set:\n",
    "                result.append(line)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función recover_from_index recorre todo el archivo 'clean_uniform_od.csv' para encontrar los datos asociados a un índice, tarda muchísimo. En vez de eso, metemos el archivo en una rdd y operamos un join a la rdd libre de errores con los índices como clave, para luego quedarnos con los datos ya limpios de cada campimetría."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_datos_derecho=sc.textFile('clean_uniform_od.csv').\\\n",
    "                        map(lambda x: (int(x.split(';')[0]),x.split(';')[1:]))\n",
    "rdd_juntada_derecho=rdd_derecho_final.flatMap(lambda x: [(i,x[:-1]) for i in x[-1]])\n",
    "rdd_combinacion_derecho=rdd_datos_derecho.join(rdd_juntada_derecho).\\\n",
    "                        mapValues(lambda x: x[1]+x[0][4:]).\\\n",
    "                        map(lambda x: ';'.join(x[1]))\n",
    "\n",
    "rdd_datos_izquierdo=sc.textFile('clean_uniform_oi.csv').\\\n",
    "                        map(lambda x: (int(x.split(';')[0]),x.split(';')[1:]))\n",
    "rdd_juntada_izquierdo=rdd_izquierdo_final.flatMap(lambda x: [(i,x[:-1]) for i in x[-1]])\n",
    "rdd_combinacion_izquierdo=rdd_datos_izquierdo.join(rdd_juntada_izquierdo).\\\n",
    "                        mapValues(lambda x: x[1]+x[0][4:]).\\\n",
    "                        map(lambda x: ';'.join(x[1]))\n",
    "\n",
    "rdd_combinacion_derecho.take(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Cuidado:* si los archivos ya existen, el comando saveAsTextFile da error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('deduplicated_uniform_od.csv', 'w') as f:\n",
    "        for line in rdd_combinacion_derecho.collect():\n",
    "            print(line, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('deduplicated_uniform_oi.csv', 'w') as f:\n",
    "        for line in rdd_combinacion_izquierdo.collect():\n",
    "            print(line, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
